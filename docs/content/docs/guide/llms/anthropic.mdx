---
title: Anthropic
description: Using Anthropic Claude models with GoFlow
---

## Supported Models

| Model | Context | Best For |
|-------|---------|----------|
| `claude-3-5-sonnet-20241022` | 200K | Best balance of intelligence and speed |
| `claude-3-5-haiku-20241022` | 200K | Extremely fast and affordable |
| `claude-3-opus-20240229` | 200K | Most capable legacy model |
| `claude-3-sonnet-20240229` | 200K | Previous generation balanced model |
| `claude-3-haiku-20240307` | 200K | Previous fast model |

## Usage

### Initialization

```go
import "github.com/nuulab/goflow/pkg/llm/anthropic"

// Default: claude-3-5-sonnet
llm := anthropic.New("")

// Specify model
llm := anthropic.New("", anthropic.WithModel("claude-3-5-haiku-20241022"))

// With custom options
llm := anthropic.New("sk-ant-your-key",
    anthropic.WithModel("claude-3-opus-20240229"),
    anthropic.WithTimeout(120*time.Second),
)
```

## System Prompts

Anthropic handles system prompts differently from user messages. GoFlow abstracts this away and automatically extracts system prompts from your message history.

```go
response, err := llm.GenerateChat(ctx, []core.Message{
    {Role: core.RoleSystem, Content: "You are a pirate."},  // Automatically extracted and sent as system prompt
    {Role: core.RoleUser, Content: "Hello!"},
})
// Response: "Ahoy, matey!"
```
